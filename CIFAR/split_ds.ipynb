{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers\n",
    "import matplotlib.pyplot as plt\n",
    "# import configparser\n",
    "import json\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from os.path import join as ospj\n",
    "import os\n",
    "from shutil import copy"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```bash\n",
    "docker container rm sl-$SLNUM ; bash ./swarm-learning/bin/run-sl        \\\n",
    "    --name=sl-$SLNUM                         \\\n",
    "    --network sl-net             \\\n",
    "    --sl-platform=TF                   \\\n",
    "    --host-ip=sl-$SLNUM                \\\n",
    "    --sn-ip=sn-$SNNUM                   \\\n",
    "    --data-dir=\"/home/yudonghan/storage/SwarmSense/CIFAR/SplitResults-1-1-1/$SLNUM\"  \\\n",
    "    --model-dir=\"/home/yudonghan/storage/SwarmSense/CIFAR/SplitResults-1-1-1/$SLNUM\"  \\\n",
    "    --model-program=densenet.py        \\\n",
    "    --apls-ip apls                 \\\n",
    "    --gpu=$GPU                        \\\n",
    "    -serverAddress spire-server            \\\n",
    "    -genJoinToken  \\\n",
    "    -e SLNUM=$SLNUM  \\\n",
    "    -e SNNUM=$SNNUM  \\\n",
    "    -e WEIGHTAGE=$WEIGHTAGE \\\n",
    "    -e TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "tmp = [('cifar10.npz', 'SplitResults-'), ('imb_cifar10.npz', 'SplitResults_LT-')]\n",
    "DS_PATH, DIR_BASE_NAME = tmp[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "loaded = np.load(DS_PATH)\n",
    "train_images = loaded['train_images']\n",
    "train_labels = loaded['train_labels']\n",
    "test_images = loaded['test_images']\n",
    "test_labels = loaded['test_labels']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train = list(zip(train_images, train_labels))\n",
    "test = list(zip(test_images, test_labels))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "np.random.seed(113)\n",
    "np.random.shuffle(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def work(lst, test_images, test_labels, weightage = [1,1,1], dir_base_name = 'SplitResults-'):\n",
    "    dir_name = dir_base_name + '-'.join(map(str, weightage))\n",
    "    if os.path.exists(dir_name):\n",
    "        print(dir_name, 'exists')\n",
    "        os.system(f'rm -rf {dir_name}')\n",
    "    os.mkdir(dir_name)\n",
    "\n",
    "    weightage = np.array(weightage)\n",
    "    weightage = weightage / weightage.sum()\n",
    "    weightage = np.cumsum(weightage)\n",
    "    weightage = len(lst) * weightage\n",
    "    weightage = np.around(weightage)\n",
    "    weightage = weightage.astype(np.int32)\n",
    "    weightage = weightage[:-1]\n",
    "    print(weightage)\n",
    "    \n",
    "    images, labels = zip(*lst)\n",
    "    image_lst = np.split(images, weightage)\n",
    "    label_lst = np.split(labels, weightage)\n",
    "    assert all(len(x) == len(y) for x,y in zip(image_lst, label_lst))\n",
    "\n",
    "    for i, (train_images, train_labels) in enumerate(zip(image_lst, label_lst)):\n",
    "        path = ospj(dir_name, str(i+1))\n",
    "        os.mkdir(path)\n",
    "        np.savez_compressed(\n",
    "            ospj(path, 'cifar10.npz'),\n",
    "            train_images=train_images,\n",
    "            train_labels=train_labels,\n",
    "            test_images=test_images,\n",
    "            test_labels=test_labels\n",
    "        )\n",
    "        print('saved', path, 'with', len(train_images), 'train images and', len(test_images), 'test images')\n",
    "    return dir_name"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "dir_name = work(train, test_images, test_labels, [1,2,3], dir_base_name=DIR_BASE_NAME)\n",
    "dir_name"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 3405 10216]\n",
      "saved SplitResults_LT-1-2-3/1 with 3405 train images and 10000 test images\n",
      "saved SplitResults_LT-1-2-3/2 with 6811 train images and 10000 test images\n",
      "saved SplitResults_LT-1-2-3/3 with 10215 train images and 10000 test images\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'SplitResults_LT-1-2-3'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for x in [1,2,3]:\n",
    "    # copy('main.py', 'SplitResults-1-1-1/{0}/main.py'.format(x))\n",
    "    copy('densenet.py', f'{dir_name}/{x}/densenet.py')\n",
    "    # json.dump(config, open('SplitResults-1-1-1/{0}/config.json'.format(x), 'w'))\n",
    "os.system('rsync -avP --exclude-from ~/.rsync_exclude ./ sei:storage/SwarmSense/CIFAR/')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "building file list ... \n",
      "148 files to consider\n",
      "./\n",
      "densenet.py\n",
      "       11116 100%    9.93MB/s    0:00:00 (xfer#1, to-check=144/148)\n",
      "imb_data.ipynb\n",
      "       25675 100%   24.49MB/s    0:00:00 (xfer#2, to-check=142/148)\n",
      "split_ds.ipynb\n",
      "        6791 100%    6.48MB/s    0:00:00 (xfer#3, to-check=138/148)\n",
      "SplitResults_LT-1-1-1/1/\n",
      "SplitResults_LT-1-1-1/2/\n",
      "SplitResults_LT-1-1-1/3/\n",
      "SplitResults_LT-1-2-3/\n",
      "SplitResults_LT-1-2-3/1/\n",
      "SplitResults_LT-1-2-3/1/cifar10.npz\n",
      "    37933268 100%   94.95MB/s    0:00:00 (xfer#4, to-check=93/148)\n",
      "SplitResults_LT-1-2-3/1/densenet.py\n",
      "       11116 100%   28.42kB/s    0:00:00 (xfer#5, to-check=92/148)\n",
      "SplitResults_LT-1-2-3/2/\n",
      "SplitResults_LT-1-2-3/2/cifar10.npz\n",
      "    47626412 100%   53.12MB/s    0:00:00 (xfer#6, to-check=90/148)\n",
      "SplitResults_LT-1-2-3/2/densenet.py\n",
      "       11116 100%   12.70kB/s    0:00:00 (xfer#7, to-check=89/148)\n",
      "SplitResults_LT-1-2-3/3/\n",
      "SplitResults_LT-1-2-3/3/cifar10.npz\n",
      "    57330643 100%   40.11MB/s    0:00:01 (xfer#8, to-check=87/148)\n",
      "SplitResults_LT-1-2-3/3/densenet.py\n",
      "       11116 100%   29.82kB/s    0:00:00 (xfer#9, to-check=86/148)\n",
      "data/\n",
      "data/MNIST/\n",
      "data/MNIST/processed/\n",
      "data/MNIST/processed/test.pt\n",
      "     7920935 100%   17.37MB/s    0:00:00 (xfer#10, to-check=21/148)\n",
      "data/MNIST/processed/training.pt\n",
      "    47520935 100%   49.86MB/s    0:00:00 (xfer#11, to-check=20/148)\n",
      "data/MNIST/raw/\n",
      "data/MNIST/raw/t10k-images-idx3-ubyte\n",
      "     7840016 100%    7.58MB/s    0:00:00 (xfer#12, to-check=18/148)\n",
      "data/MNIST/raw/t10k-labels-idx1-ubyte\n",
      "       10008 100%    9.90kB/s    0:00:00 (xfer#13, to-check=17/148)\n",
      "data/MNIST/raw/train-images-idx3-ubyte\n",
      "    47040016 100%   30.52MB/s    0:00:01 (xfer#14, to-check=16/148)\n",
      "data/MNIST/raw/train-labels-idx1-ubyte\n",
      "       60008 100%  124.16kB/s    0:00:00 (xfer#15, to-check=15/148)\n",
      "\n",
      "sent 253373824 bytes  received 848 bytes  56305482.67 bytes/sec\n",
      "total size is 1817947907  speedup is 7.17\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "config = json.load(open('config.json'))\n",
    "config['base_name'] = config['base_name'].replace('CL', 'SL')\n",
    "config['sl'] = True\n",
    "print(config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.system('jupyter nbconvert --to python main.ipynb')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dir_name = work(train, test_images, test_labels, [1,3,9])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "config = json.load(open('config.json'))\n",
    "config['base_name'].replace('CL', 'LL')\n",
    "print(config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for x in [1,2,3]:\n",
    "    copy('main.py', 'SplitResults-1-3-9/{0}/main.py'.format(x))\n",
    "    copy('densenet.py', 'SplitResults-1-3-9/{0}/densenet.py'.format(x))\n",
    "    json.dump(config, open('SplitResults-1-3-9/{0}/config.json'.format(x), 'w'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('python39': conda)"
  },
  "interpreter": {
   "hash": "a4cb7d616bfb3a17907725a4a53e58273ef9a6a96e08090c3a7874ada81a7810"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}