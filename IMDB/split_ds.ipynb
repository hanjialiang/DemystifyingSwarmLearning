{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import shutil"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "NUM_WORDS=8000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-27 16:23:46.397395: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-27 16:23:47.463107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10727 MB memory:  -> device: 0, name: NVIDIA Tesla M40, pci bus id: 0000:08:00.0, compute capability: 5.2\n",
      "2021-09-27 16:23:47.464343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10727 MB memory:  -> device: 1, name: NVIDIA Tesla M40, pci bus id: 0000:09:00.0, compute capability: 5.2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=NUM_WORDS)\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=256, padding='post')\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=256, padding='post')\n",
    "_X_train = X_train.copy()\n",
    "_X_test = X_test.copy()\n",
    "_y_train = y_train.copy()\n",
    "_y_test = y_test.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(len(X_train))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ1-Split-1-1-1-1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "tf.random.set_seed(233)\n",
    "np.random.seed(233)\n",
    "random.seed(233)\n",
    "X_train, X_test, y_train, y_test = _X_train.copy(), _X_test.copy(), _y_train.copy(), _y_test.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tmp = list(zip(X_train, y_train))\n",
    "random.shuffle(tmp)\n",
    "X_train, y_train = zip(*tmp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "PARTS=4\n",
    "X_train_splits = np.array_split(X_train, PARTS)\n",
    "y_train_splits = np.array_split(y_train, PARTS)\n",
    "dir_names = [os.path.join('RQ1-IMDB-SplitResults', str(i)) for i in range(PARTS)]\n",
    "print(dir_names)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['RQ1-IMDB-SplitResults/0', 'RQ1-IMDB-SplitResults/1', 'RQ1-IMDB-SplitResults/2', 'RQ1-IMDB-SplitResults/3']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "splits = list(zip(X_train_splits, y_train_splits, dir_names))\n",
    "print(len(splits))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for X, y, dir_name in splits:\n",
    "    file_name = os.path.join(dir_name, 'imdb_data.npz')\n",
    "    pathlib.Path(dir_name).mkdir(parents=True, exist_ok=True)\n",
    "    np.savez(file_name, X_train=X, y_train=y, X_test=X_test, y_test=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "for dir_name in dir_names:\n",
    "    shutil.copyfile('main.py', os.path.join(dir_name, 'main.py'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ2-Split-1-2-3-4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "tf.random.set_seed(233)\n",
    "np.random.seed(233)\n",
    "random.seed(233)\n",
    "X_train, X_test, y_train, y_test = _X_train.copy(), _X_test.copy(), _y_train.copy(), _y_test.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "weightage = np.array([1,2,3,4])\n",
    "weightage = weightage / weightage.sum()\n",
    "weightage = (weightage * len(X_train)).astype(np.int)\n",
    "weightage = weightage.cumsum()[:-1]\n",
    "weightage"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 2500,  7500, 15000])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "tmp = list(zip(X_train, y_train))\n",
    "random.shuffle(tmp)\n",
    "X_train, y_train = zip(*tmp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X_train_splits = np.split(X_train, weightage)\n",
    "y_train_splits = np.split(y_train, weightage)\n",
    "dir_names = [os.path.join('RQ2-IMDB-SplitResults', str(i)) for i in range(len(weightage) + 1)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "splits = list(zip(X_train_splits, y_train_splits, dir_names))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "for X, y, dir_name in splits:\n",
    "    file_name = os.path.join(dir_name, 'imdb_data.npz')\n",
    "    pathlib.Path(dir_name).mkdir(parents=True, exist_ok=True)\n",
    "    np.savez(file_name, X_train=X, y_train=y, X_test=X_test, y_test=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "for dir_name in dir_names:\n",
    "    shutil.copyfile('main.py', os.path.join(dir_name, 'main.py'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ2-Split-LT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "tf.random.set_seed(233)\n",
    "np.random.seed(233)\n",
    "random.seed(233)\n",
    "X_train, X_test, y_train, y_test = _X_train.copy(), _X_test.copy(), _y_train.copy(), _y_test.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "idx_0 = np.where(y_train==0)[0]\n",
    "idx_1 = np.where(y_train==1)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "y_train==1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True, False, False, ..., False,  True, False])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "np.random.shuffle(idx_0)\n",
    "np.random.shuffle(idx_1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "idx_0 = np.random.choice(idx_0, 12000)\n",
    "idx_1 = np.random.choice(idx_1, 4000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "idx = np.concatenate((idx_0, idx_1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "splits_idx = np.array(list(np.concatenate((x,y)) for x,y in zip(np.split(idx_0, 4), np.split(idx_1, 4))))\n",
    "X_train_splits = X_train[splits_idx]\n",
    "y_train_splits = y_train[splits_idx]\n",
    "dir_names = [os.path.join('RQ2-IMDB_LT-SplitResults', str(i)) for i in range(4)]\n",
    "splits = list(zip(X_train_splits, y_train_splits, dir_names))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "dir_name_all = os.path.join('RQ2-IMDB_LT-SplitResults', 'all')\n",
    "pathlib.Path(dir_name_all).mkdir(parents=True, exist_ok=True)\n",
    "shutil.copyfile('main.py', os.path.join(dir_name_all, 'main.py'))\n",
    "file_name = os.path.join(dir_name_all, 'imdb_data.npz')\n",
    "np.savez(file_name, X_train=X_train[idx], y_train=y_train[idx], X_test=X_test, y_test=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "for X, y, dir_name in splits:\n",
    "    file_name = os.path.join(dir_name, 'imdb_data.npz')\n",
    "    pathlib.Path(dir_name).mkdir(parents=True, exist_ok=True)\n",
    "    np.savez(file_name, X_train=X, y_train=y, X_test=X_test, y_test=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "for dir_name in dir_names:\n",
    "    shutil.copyfile('main.py', os.path.join(dir_name, 'main.py'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RQ4-Low-Quality"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "tf.random.set_seed(233)\n",
    "np.random.seed(233)\n",
    "random.seed(233)\n",
    "X_train, X_test, y_train, y_test = _X_train.copy(), _X_test.copy(), _y_train.copy(), _y_test.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "tmp = list(zip(X_train, y_train))\n",
    "random.shuffle(tmp)\n",
    "X_train, y_train = zip(*tmp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "PARTS=4\n",
    "X_train_splits = np.array_split(X_train, PARTS)\n",
    "y_train_splits = np.array_split(y_train, PARTS)\n",
    "dir_names = [os.path.join('RQ4-IMDB-SplitResults', str(i)) for i in range(PARTS)]\n",
    "print(dir_names)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['RQ4-IMDB-SplitResults/0', 'RQ4-IMDB-SplitResults/1', 'RQ4-IMDB-SplitResults/2', 'RQ4-IMDB-SplitResults/3']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "y_train_splits[3] = np.bitwise_xor(y_train_splits[3], np.random.binomial(1, 0.5, len(y_train_splits[3])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "splits = list(zip(X_train_splits, y_train_splits, dir_names))\n",
    "print(len(splits))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "for X, y, dir_name in splits:\n",
    "    file_name = os.path.join(dir_name, 'imdb_data.npz')\n",
    "    pathlib.Path(dir_name).mkdir(parents=True, exist_ok=True)\n",
    "    np.savez(file_name, X_train=X, y_train=y, X_test=X_test, y_test=y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "for dir_name in dir_names:\n",
    "    shutil.copyfile('main.py', os.path.join(dir_name, 'main.py'))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52a079963e38228ed734f54d1ebee41619fc95dafab7a163594b2ca78783b21a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('work': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}