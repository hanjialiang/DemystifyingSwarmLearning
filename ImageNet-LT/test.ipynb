{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['HTTPS_PROXY', 'HTTP_PROXY', 'https_proxy', 'http_proxy']:\n",
    "    os.environ[name] = 'http://162.105.175.156:3434'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['data/ImageNet_LT_test.txt', 'data/ImageNet_LT_val.txt', 'data/ImageNet_LT_train.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(file_paths[2], dtype={1:str}, sep=' ', header=None, converters={0:lambda x:'data/'+x})\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = plt.imread(df[0][333])\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_and_cast_label(x):\n",
    "    path = x[0]\n",
    "    label = x[1]\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = K.applications.efficientnet.preprocess_input(image)\n",
    "    # image = tf.image.per_image_standardization(image)\n",
    "    label = tf.strings.to_number(label, out_type=tf.int32)\n",
    "    one_hot = tf.one_hot(label, depth=1000)\n",
    "    return image, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset, training=False, batch_size=32):\n",
    "    ds = dataset.map(read_image_and_cast_label)\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "        ds = ds.repeat()\n",
    "    ds = ds.batch(batch_size)\n",
    "    # 当模型在训练的时候，`prefetch` 使数据集在后台取得 batch。\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imagenet_dataset(path, training=False, batch_size=32):\n",
    "    df = pd.read_csv(path, dtype={1:str}, sep=' ', header=None, converters={0:lambda x:'data/'+x})\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(df)\n",
    "    dataset = process_dataset(dataset, training, batch_size)\n",
    "    return dataset, len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs=200\n",
    "batch_size=32\n",
    "\n",
    "model_name = \"EfficientNetB1-Imagenet_LT\"\n",
    "current_name = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_tot = read_imagenet_dataset(file_paths[2], True, batch_size)\n",
    "val_ds, val_tot = read_imagenet_dataset(file_paths[1], False, batch_size)\n",
    "steps_per_epoch = (train_tot+batch_size-1)//batch_size\n",
    "\n",
    "# Swarm learning config\n",
    "SWARM_LEARNING=False\n",
    "swSyncInterval = steps_per_epoch * 5\n",
    "min_peers = 3\n",
    "\n",
    "if SWARM_LEARNING:\n",
    "    current_name += '-SL{0}-interval{1}-peers{2}'.format(os.getenv('SLNUM'), swSyncInterval, min_peers)\n",
    "else:\n",
    "    current_name += '-baseline'\n",
    "    \n",
    "current_name += datetime.now().strftime(\"-%Y%m%d%H%M%S\")\n",
    "current_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = K.applications.EfficientNetB1(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[\n",
    "    K.callbacks.TensorBoard(\n",
    "        log_dir=\"logs/profile/\" + current_name,\n",
    "        profile_batch=5\n",
    "    ),\n",
    "    K.callbacks.EarlyStopping(patience=8, restore_best_weights=True),\n",
    "    K.callbacks.ModelCheckpoint('saved_models/' + current_name, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=max_epochs,\n",
    "    validation_data=val_ds,\n",
    "    validation_freq=1,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
